{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teamcenter AI Agent Setup Testing\n",
    "\n",
    "This notebook tests your setup step-by-step safely.\n",
    "\n",
    "**Important**: Run cells one by one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configuration Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: CONFIGURATION LOADING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from config import Config\n",
    "    print(\"‚úì Configuration module imported successfully\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Project Configuration:\")\n",
    "    print(f\"   Project Root: {Config.PROJECT_ROOT}\")\n",
    "    print(f\"   Data Directory: {Config.DATA_DIR}\")\n",
    "    print(f\"   Documents Directory: {Config.DOCUMENTS_DIR}\")\n",
    "    \n",
    "    print(f\"\\nü§ñ AI Model Configuration:\")\n",
    "    print(f\"   Primary Model: {Config.PRIMARY_MODEL}\")\n",
    "    print(f\"   Embedding Model: {Config.EMBEDDING_MODEL}\")\n",
    "    print(f\"   Max Tokens: {Config.MAX_TOKENS}\")\n",
    "    print(f\"   Temperature: {Config.TEMPERATURE}\")\n",
    "    \n",
    "    print(f\"\\nüîß RAG Configuration:\")\n",
    "    print(f\"   Chunk Size: {Config.CHUNK_SIZE}\")\n",
    "    print(f\"   Chunk Overlap: {Config.CHUNK_OVERLAP}\")\n",
    "    print(f\"   Top-K Retrieval: {Config.TOP_K_RETRIEVAL}\")\n",
    "    \n",
    "    # Check API keys with more detail\n",
    "    print(f\"\\nüîë API Key Status:\")\n",
    "    \n",
    "    if Config.ANTHROPIC_API_KEY:\n",
    "        key_preview = Config.ANTHROPIC_API_KEY[:20] + \"...\" + Config.ANTHROPIC_API_KEY[-10:]\n",
    "        print(f\"   Anthropic: ‚úì SET ({len(Config.ANTHROPIC_API_KEY)} chars) - {key_preview}\")\n",
    "    else:\n",
    "        print(f\"   Anthropic: ‚úó MISSING\")\n",
    "        \n",
    "    if Config.LANGFUSE_PUBLIC_KEY and Config.LANGFUSE_SECRET_KEY:\n",
    "        pub_preview = Config.LANGFUSE_PUBLIC_KEY[:15] + \"...\"\n",
    "        sec_preview = Config.LANGFUSE_SECRET_KEY[:15] + \"...\"\n",
    "        print(f\"   Langfuse Public: ‚úì SET ({len(Config.LANGFUSE_PUBLIC_KEY)} chars) - {pub_preview}\")\n",
    "        print(f\"   Langfuse Secret: ‚úì SET ({len(Config.LANGFUSE_SECRET_KEY)} chars) - {sec_preview}\")\n",
    "        print(f\"   Langfuse Host: {Config.LANGFUSE_HOST}\")\n",
    "    else:\n",
    "        print(f\"   Langfuse: ‚úó MISSING\")\n",
    "        \n",
    "    if Config.OPENAI_API_KEY:\n",
    "        openai_preview = Config.OPENAI_API_KEY[:20] + \"...\" + Config.OPENAI_API_KEY[-10:]\n",
    "        print(f\"   OpenAI: ‚úì SET ({len(Config.OPENAI_API_KEY)} chars) - {openai_preview}\")\n",
    "    else:\n",
    "        print(f\"   OpenAI: ‚óã NOT SET (optional)\")\n",
    "        \n",
    "    if Config.GOOGLE_API_KEY:\n",
    "        google_preview = Config.GOOGLE_API_KEY[:20] + \"...\"\n",
    "        print(f\"   Google: ‚úì SET ({len(Config.GOOGLE_API_KEY)} chars) - {google_preview}\")\n",
    "    else:\n",
    "        print(f\"   Google: ‚óã NOT SET (optional)\")\n",
    "    \n",
    "    # Validate configuration\n",
    "    print(f\"\\nüîç Configuration Validation:\")\n",
    "    errors = Config.validate_config()\n",
    "    if errors:\n",
    "        print(\"   ‚ö†Ô∏è Issues found:\")\n",
    "        for i, error in enumerate(errors, 1):\n",
    "            print(f\"      {i}. {error}\")\n",
    "    else:\n",
    "        print(\"   ‚úì All validation checks passed!\")\n",
    "        \n",
    "    print(f\"\\n‚úÖ CONFIGURATION TEST: PASSED\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå CONFIGURATION TEST: FAILED\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(f\"\\nFull traceback:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Dependencies Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing core dependencies...\")\n",
    "\n",
    "dependencies = [\n",
    "    ('anthropic', 'Anthropic Claude API'),\n",
    "    ('langfuse', 'Langfuse experiment tracking'),\n",
    "    ('sentence_transformers', 'Sentence Transformers'),\n",
    "    ('faiss', 'FAISS vector database'),\n",
    "    ('numpy', 'NumPy'),\n",
    "    ('pandas', 'Pandas')\n",
    "]\n",
    "\n",
    "success_count = 0\n",
    "for package, description in dependencies:\n",
    "    try:\n",
    "        if package == 'faiss':\n",
    "            import faiss\n",
    "        else:\n",
    "            __import__(package)\n",
    "        print(f\"SUCCESS: {description}\")\n",
    "        success_count += 1\n",
    "    except ImportError as e:\n",
    "        print(f\"FAILED: {description}: {e}\")\n",
    "\n",
    "print(f\"\\nResult: {success_count}/{len(dependencies)} dependencies OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Anthropic API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 3: ANTHROPIC API TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚ö†Ô∏è This will likely fail due to insufficient credits - that's expected!\")\n",
    "\n",
    "try:\n",
    "    import anthropic\n",
    "    from config import Config\n",
    "    import json\n",
    "    \n",
    "    if not Config.ANTHROPIC_API_KEY:\n",
    "        print(\"‚ùå FAILED: No Anthropic API key found in configuration\")\n",
    "        print(\"üí° Check your .env file and ensure ANTHROPIC_API_KEY is set\")\n",
    "    else:\n",
    "        print(\"üîë Anthropic API key found in configuration\")\n",
    "        key_preview = Config.ANTHROPIC_API_KEY[:20] + \"...\" + Config.ANTHROPIC_API_KEY[-10:]\n",
    "        print(f\"   Key preview: {key_preview}\")\n",
    "        print(f\"   Key length: {len(Config.ANTHROPIC_API_KEY)} characters\")\n",
    "        \n",
    "        print(\"\\nüì° Creating Anthropic client...\")\n",
    "        client = anthropic.Anthropic(api_key=Config.ANTHROPIC_API_KEY)\n",
    "        print(\"‚úì Client created successfully\")\n",
    "        \n",
    "        print(\"\\nüöÄ Sending test request to Claude...\")\n",
    "        print(\"   Model: claude-3-haiku-20240307\")\n",
    "        print(\"   Max tokens: 50\")\n",
    "        print(\"   Message: 'Hello! Please respond with your name and confirm this API test is working.'\")\n",
    "        \n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=50,\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"Hello! Please respond with your name and confirm this API test is working.\"\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        print(\"\\n‚úÖ SUCCESS: Anthropic API is working!\")\n",
    "        print(\"\\nüìù Full Response Details:\")\n",
    "        print(f\"   Model used: {response.model}\")\n",
    "        print(f\"   Response ID: {response.id}\")\n",
    "        print(f\"   Stop reason: {response.stop_reason}\")\n",
    "        \n",
    "        print(\"\\nüí¨ Claude's Response:\")\n",
    "        print(f\"   '{response.content[0].text}'\")\n",
    "        \n",
    "        print(\"\\nüìä Token Usage:\")\n",
    "        print(f\"   Input tokens: {response.usage.input_tokens}\")\n",
    "        print(f\"   Output tokens: {response.usage.output_tokens}\")\n",
    "        print(f\"   Total tokens: {response.usage.input_tokens + response.usage.output_tokens}\")\n",
    "        \n",
    "        # Estimate cost (approximate)\n",
    "        input_cost = response.usage.input_tokens * 0.00025 / 1000  # $0.25 per 1K tokens\n",
    "        output_cost = response.usage.output_tokens * 0.00125 / 1000  # $1.25 per 1K tokens\n",
    "        total_cost = input_cost + output_cost\n",
    "        print(f\"   Estimated cost: ${total_cost:.6f}\")\n",
    "        \n",
    "        print(\"\\nüéâ ANTHROPIC API TEST: PASSED\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: Anthropic API test failed\")\n",
    "    print(f\"\\nüîç Error Details:\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    print(f\"   Error message: {str(e)}\")\n",
    "    \n",
    "    # Parse different types of errors\n",
    "    error_str = str(e).lower()\n",
    "    \n",
    "    if \"credit balance\" in error_str or \"insufficient\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Insufficient credits in Anthropic account\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Go to: https://console.anthropic.com/settings/billing\")\n",
    "        print(\"   2. Add at least $5-10 in credits\")\n",
    "        print(\"   3. Wait a few minutes for credits to be processed\")\n",
    "        print(\"   4. Re-run this test\")\n",
    "        print(\"\\nüìã This is the EXPECTED error - nothing is broken!\")\n",
    "        \n",
    "    elif \"authentication\" in error_str or \"api key\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: API key authentication issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your .env file\")\n",
    "        print(\"   2. Verify ANTHROPIC_API_KEY is correct\")\n",
    "        print(\"   3. Get new key from: https://console.anthropic.com/settings/keys\")\n",
    "        \n",
    "    elif \"network\" in error_str or \"connection\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Network connectivity issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your internet connection\")\n",
    "        print(\"   2. Try again in a few minutes\")\n",
    "        print(\"   3. Check if corporate firewall is blocking the request\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nüí° DIAGNOSIS: Unexpected error\")\n",
    "        print(f\"\\nüîß SOLUTION:\")\n",
    "        print(f\"   1. Try again in a few minutes\")\n",
    "        print(f\"   2. Check Anthropic status page\")\n",
    "        print(f\"   3. Verify your API key is valid\")\n",
    "    \n",
    "    print(\"\\n‚ùå ANTHROPIC API TEST: FAILED (but this might be expected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Langfuse Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 4: LANGFUSE CONNECTION TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    from langfuse import Langfuse\n",
    "    from config import Config\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    \n",
    "    if not Config.LANGFUSE_PUBLIC_KEY or not Config.LANGFUSE_SECRET_KEY:\n",
    "        print(\"‚ùå FAILED: Langfuse keys not found in configuration\")\n",
    "        print(\"üí° Check your .env file for LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY\")\n",
    "    else:\n",
    "        print(\"üîë Langfuse keys found in configuration\")\n",
    "        pub_preview = Config.LANGFUSE_PUBLIC_KEY[:15] + \"...\"\n",
    "        sec_preview = Config.LANGFUSE_SECRET_KEY[:15] + \"...\"\n",
    "        print(f\"   Public key: {pub_preview} ({len(Config.LANGFUSE_PUBLIC_KEY)} chars)\")\n",
    "        print(f\"   Secret key: {sec_preview} ({len(Config.LANGFUSE_SECRET_KEY)} chars)\")\n",
    "        print(f\"   Host: {Config.LANGFUSE_HOST}\")\n",
    "        \n",
    "        print(\"\\nüì° Creating Langfuse client...\")\n",
    "        langfuse = Langfuse(\n",
    "            public_key=Config.LANGFUSE_PUBLIC_KEY,\n",
    "            secret_key=Config.LANGFUSE_SECRET_KEY,\n",
    "            host=Config.LANGFUSE_HOST\n",
    "        )\n",
    "        print(\"‚úì Langfuse client created successfully\")\n",
    "        \n",
    "        print(\"\\nüß™ Testing authentication with auth check...\")\n",
    "        try:\n",
    "            auth_result = langfuse.auth_check()\n",
    "            print(\"‚úì Authentication successful\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"‚ö†Ô∏è Auth check failed: {auth_error}\")\n",
    "        \n",
    "        print(\"\\nüéØ Creating a test trace for tracking...\")\n",
    "        test_timestamp = datetime.now().isoformat()\n",
    "        \n",
    "        # Create a trace first\n",
    "        trace = langfuse.start_span(\n",
    "            name=\"setup_verification_trace\",\n",
    "            metadata={\n",
    "                \"setup_phase\": \"initial_testing\",\n",
    "                \"components_tested\": [\"config\", \"dependencies\", \"anthropic\", \"langfuse\"],\n",
    "                \"timestamp\": test_timestamp,\n",
    "                \"test_type\": \"setup_verification\",\n",
    "                \"project\": \"teamcenter_ai_agent\",\n",
    "                \"version\": \"1.0.0\"\n",
    "            }\n",
    "        )\n",
    "        print(\"‚úì Test trace created successfully\")\n",
    "        \n",
    "        print(\"\\nüìä Trace Details:\")\n",
    "        if hasattr(trace, 'id'):\n",
    "            print(f\"   Trace ID: {trace.id}\")\n",
    "        print(f\"   Test name: setup_verification_trace\")\n",
    "        print(f\"   Timestamp: {test_timestamp}\")\n",
    "        \n",
    "        print(\"\\nüß™ Creating test generation within trace...\")\n",
    "        generation = langfuse.start_generation(\n",
    "            name=\"setup_test_detailed\",\n",
    "            model=\"test-model-v1\", \n",
    "            input=\"This is a setup test to verify Langfuse connectivity and tracking capabilities\",\n",
    "            metadata={\n",
    "                \"test_type\": \"setup_verification\",\n",
    "                \"test_timestamp\": test_timestamp,\n",
    "                \"project\": \"teamcenter_ai_agent\",\n",
    "                \"version\": \"1.0.0\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Complete the generation\n",
    "        generation.end(\n",
    "            output=\"Setup test completed successfully - Langfuse is working properly\"\n",
    "        )\n",
    "        print(\"‚úì Test generation created and completed\")\n",
    "        \n",
    "        print(\"\\n‚è±Ô∏è Waiting for Langfuse to process...\")\n",
    "        time.sleep(2)  # Give Langfuse time to process\n",
    "        \n",
    "        # Complete the trace\n",
    "        trace.end()\n",
    "        print(\"‚úì Trace completed successfully\")\n",
    "        \n",
    "        print(\"\\n‚úÖ SUCCESS: Langfuse connection and tracking working!\")\n",
    "        print(\"\\nüìã What was tested:\")\n",
    "        print(\"   ‚úì API key authentication\")\n",
    "        print(\"   ‚úì Client initialization\")\n",
    "        print(\"   ‚úì Authentication check\")\n",
    "        print(\"   ‚úì Trace creation\")\n",
    "        print(\"   ‚úì Generation creation and completion\")\n",
    "        print(\"   ‚úì Metadata attachment\")\n",
    "        \n",
    "        print(\"\\nüåê You can view these test entries in your Langfuse dashboard:\")\n",
    "        print(f\"   Dashboard: {Config.LANGFUSE_HOST}\")\n",
    "        \n",
    "        print(\"\\nüéâ LANGFUSE TEST: PASSED\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: Langfuse test failed\")\n",
    "    print(f\"\\nüîç Error Details:\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    print(f\"   Error message: {str(e)}\")\n",
    "    \n",
    "    # Parse different types of errors\n",
    "    error_str = str(e).lower()\n",
    "    \n",
    "    if \"unauthorized\" in error_str or \"authentication\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: API key authentication issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your .env file\")\n",
    "        print(\"   2. Verify LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY are correct\")\n",
    "        print(\"   3. Get new keys from your Langfuse project settings\")\n",
    "        print(\"   4. Ensure you're using the right host URL\")\n",
    "        \n",
    "    elif \"connection\" in error_str or \"network\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Network connectivity issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your internet connection\")\n",
    "        print(\"   2. Verify the Langfuse host URL is correct\")\n",
    "        print(\"   3. Check if corporate firewall is blocking the request\")\n",
    "        \n",
    "    elif \"timeout\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Request timeout\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Try again - this might be temporary\")\n",
    "        print(\"   2. Check Langfuse service status\")\n",
    "        print(\"   3. Verify your host URL is correct\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nüí° DIAGNOSIS: Unexpected error\")\n",
    "        print(f\"\\nüîß SOLUTION:\")\n",
    "        print(f\"   1. Check Langfuse documentation\")\n",
    "        print(f\"   2. Verify your project settings\")\n",
    "        print(f\"   3. Try again in a few minutes\")\n",
    "    \n",
    "    print(\"\\nüîç Full traceback:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    print(\"\\n‚ùå LANGFUSE TEST: FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: OpenAI API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 5: OPENAI API TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üîß Testing fallback/comparison API - OpenAI GPT models\")\n",
    "\n",
    "try:\n",
    "    import openai\n",
    "    from config import Config\n",
    "    import json\n",
    "    \n",
    "    if not Config.OPENAI_API_KEY:\n",
    "        print(\"‚óã SKIPPED: No OpenAI API key found in configuration\")\n",
    "        print(\"üí° This is optional - OpenAI is used as fallback/comparison model\")\n",
    "        print(\"üîß To test OpenAI:\")\n",
    "        print(\"   1. Get API key from: https://platform.openai.com/account/api-keys\")\n",
    "        print(\"   2. Add OPENAI_API_KEY to your .env file\")\n",
    "        print(\"   3. Re-run this test\")\n",
    "        print(\"\\n‚úÖ OPENAI TEST: SKIPPED (OPTIONAL)\")\n",
    "    else:\n",
    "        print(\"üîë OpenAI API key found in configuration\")\n",
    "        key_preview = Config.OPENAI_API_KEY[:20] + \"...\" + Config.OPENAI_API_KEY[-10:]\n",
    "        print(f\"   Key preview: {key_preview}\")\n",
    "        print(f\"   Key length: {len(Config.OPENAI_API_KEY)} characters\")\n",
    "        \n",
    "        print(\"\\nüì° Creating OpenAI client...\")\n",
    "        client = openai.OpenAI(api_key=Config.OPENAI_API_KEY)\n",
    "        print(\"‚úì OpenAI client created successfully\")\n",
    "        \n",
    "        print(\"\\nüöÄ Sending test request to GPT...\")\n",
    "        print(\"   Model: gpt-3.5-turbo\")\n",
    "        print(\"   Max tokens: 50\")\n",
    "        print(\"   Message: 'Hello! Please confirm this OpenAI API test is working and tell me your model name.'\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            max_tokens=50,\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"Hello! Please confirm this OpenAI API test is working and tell me your model name.\"\n",
    "            }],\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        print(\"\\n‚úÖ SUCCESS: OpenAI API is working!\")\n",
    "        print(\"\\nüìù Full Response Details:\")\n",
    "        print(f\"   Model used: {response.model}\")\n",
    "        print(f\"   Response ID: {response.id}\")\n",
    "        print(f\"   Object type: {response.object}\")\n",
    "        print(f\"   Finish reason: {response.choices[0].finish_reason}\")\n",
    "        \n",
    "        print(\"\\nüí¨ GPT's Response:\")\n",
    "        print(f\"   '{response.choices[0].message.content}'\")\n",
    "        \n",
    "        print(\"\\nüìä Token Usage:\")\n",
    "        usage = response.usage\n",
    "        print(f\"   Prompt tokens: {usage.prompt_tokens}\")\n",
    "        print(f\"   Completion tokens: {usage.completion_tokens}\")\n",
    "        print(f\"   Total tokens: {usage.total_tokens}\")\n",
    "        \n",
    "        # Estimate cost for GPT-3.5-turbo (approximate)\n",
    "        prompt_cost = usage.prompt_tokens * 0.0015 / 1000  # $0.0015 per 1K tokens\n",
    "        completion_cost = usage.completion_tokens * 0.002 / 1000  # $0.002 per 1K tokens\n",
    "        total_cost = prompt_cost + completion_cost\n",
    "        print(f\"   Estimated cost: ${total_cost:.6f}\")\n",
    "        \n",
    "        print(\"\\nüéØ Testing model capabilities...\")\n",
    "        \n",
    "        # Test with a more complex request\n",
    "        print(\"   Testing reasoning with a simple math problem...\")\n",
    "        math_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            max_tokens=30,\n",
    "            messages=[{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"What is 15 + 27? Please show the calculation.\"\n",
    "            }],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        print(f\"   Math response: '{math_response.choices[0].message.content}'\")\n",
    "        print(f\"   Additional tokens used: {math_response.usage.total_tokens}\")\n",
    "        \n",
    "        print(\"\\nüéâ OPENAI API TEST: PASSED\")\n",
    "        print(\"\\nüìã Capabilities verified:\")\n",
    "        print(\"   ‚úì API authentication\")\n",
    "        print(\"   ‚úì Chat completion generation\")\n",
    "        print(\"   ‚úì Token usage tracking\")\n",
    "        print(\"   ‚úì Response formatting\")\n",
    "        print(\"   ‚úì Basic reasoning/math\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: OpenAI API test failed\")\n",
    "    print(f\"\\nüîç Error Details:\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    print(f\"   Error message: {str(e)}\")\n",
    "    \n",
    "    # Parse different types of errors\n",
    "    error_str = str(e).lower()\n",
    "    \n",
    "    if \"invalid api key\" in error_str or \"authentication\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: API key authentication issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your .env file\")\n",
    "        print(\"   2. Verify OPENAI_API_KEY is correct\")\n",
    "        print(\"   3. Get new key from: https://platform.openai.com/account/api-keys\")\n",
    "        print(\"   4. Ensure you have credits in your OpenAI account\")\n",
    "        \n",
    "    elif \"insufficient\" in error_str or \"quota\" in error_str or \"billing\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Insufficient credits or quota exceeded\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your OpenAI billing: https://platform.openai.com/account/billing\")\n",
    "        print(\"   2. Add credits to your account\")\n",
    "        print(\"   3. Check your usage limits\")\n",
    "        \n",
    "    elif \"rate limit\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Rate limit exceeded\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Wait a minute and try again\")\n",
    "        print(\"   2. Check your rate limits in OpenAI dashboard\")\n",
    "        print(\"   3. Consider upgrading your plan for higher limits\")\n",
    "        \n",
    "    elif \"connection\" in error_str or \"network\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Network connectivity issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your internet connection\")\n",
    "        print(\"   2. Try again in a few minutes\")\n",
    "        print(\"   3. Check if corporate firewall is blocking OpenAI\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nüí° DIAGNOSIS: Unexpected error\")\n",
    "        print(f\"\\nüîß SOLUTION:\")\n",
    "        print(f\"   1. Check OpenAI status page\")\n",
    "        print(f\"   2. Verify your API key is valid\")\n",
    "        print(f\"   3. Try again in a few minutes\")\n",
    "    \n",
    "    print(\"\\nüîç Full traceback:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    print(\"\\n‚ùå OPENAI API TEST: FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Google Gemini API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 6: GOOGLE GEMINI API TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üîß Testing fallback/comparison API - Google Gemini models\")\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    from config import Config\n",
    "    import json\n",
    "    \n",
    "    if not Config.GOOGLE_API_KEY:\n",
    "        print(\"‚óã SKIPPED: No Google API key found in configuration\")\n",
    "        print(\"üí° This is optional - Google Gemini is used as fallback/comparison model\")\n",
    "        print(\"üîß To test Google Gemini:\")\n",
    "        print(\"   1. Get API key from: https://console.cloud.google.com/apis/credentials\")\n",
    "        print(\"   2. Enable the Generative AI API\")\n",
    "        print(\"   3. Add GOOGLE_API_KEY to your .env file\")\n",
    "        print(\"   4. Re-run this test\")\n",
    "        print(\"\\n‚úÖ GOOGLE GEMINI TEST: SKIPPED (OPTIONAL)\")\n",
    "    else:\n",
    "        print(\"üîë Google API key found in configuration\")\n",
    "        key_preview = Config.GOOGLE_API_KEY[:20] + \"...\"\n",
    "        print(f\"   Key preview: {key_preview}\")\n",
    "        print(f\"   Key length: {len(Config.GOOGLE_API_KEY)} characters\")\n",
    "        \n",
    "        print(\"\\nüì° Configuring Google Generative AI...\")\n",
    "        genai.configure(api_key=Config.GOOGLE_API_KEY)\n",
    "        print(\"‚úì Google AI client configured successfully\")\n",
    "        \n",
    "        print(\"\\nüîç Getting available models...\")\n",
    "        try:\n",
    "            models = list(genai.list_models())\n",
    "            available_models = [m.name for m in models if 'generateContent' in m.supported_generation_methods]\n",
    "            print(f\"   Found {len(available_models)} available models\")\n",
    "            if available_models:\n",
    "                print(f\"   First few models: {available_models[:3]}\")\n",
    "        except Exception as model_error:\n",
    "            print(f\"   Could not list models: {model_error}\")\n",
    "            available_models = ['models/gemini-1.5-pro', 'models/gemini-pro']  # fallback\n",
    "        \n",
    "        print(\"\\nüöÄ Sending test request to Gemini...\")\n",
    "        # Try the most current model first, fallback to older version\n",
    "        if \"models/gemini-1.5-pro\" in available_models:\n",
    "            model_name = \"gemini-1.5-pro\"\n",
    "        elif \"models/gemini-pro\" in available_models:\n",
    "            model_name = \"gemini-pro\"\n",
    "        else:\n",
    "            model_name = \"gemini-1.5-pro\"  # Default to current version\n",
    "            \n",
    "        print(f\"   Model: {model_name}\")\n",
    "        print(\"   Message: 'Hello! Please confirm this Google Gemini API test is working and tell me about your capabilities.'\")\n",
    "\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        response = model.generate_content(\n",
    "            \"Hello! Please confirm this Google Gemini API test is working and tell me about your capabilities.\",\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                max_output_tokens=100,\n",
    "                temperature=0.1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(\"\\n‚úÖ SUCCESS: Google Gemini API is working!\")\n",
    "        print(\"\\nüìù Full Response Details:\")\n",
    "        print(f\"   Model used: {model_name}\")\n",
    "        \n",
    "        # Check if response has the expected attributes\n",
    "        if hasattr(response, 'text'):\n",
    "            print(f\"   Response text available: Yes\")\n",
    "            print(f\"   Response length: {len(response.text)} characters\")\n",
    "        \n",
    "        if hasattr(response, 'candidates'):\n",
    "            print(f\"   Number of candidates: {len(response.candidates)}\")\n",
    "            if response.candidates:\n",
    "                candidate = response.candidates[0]\n",
    "                if hasattr(candidate, 'finish_reason'):\n",
    "                    print(f\"   Finish reason: {candidate.finish_reason}\")\n",
    "                if hasattr(candidate, 'safety_ratings'):\n",
    "                    print(f\"   Safety ratings: {len(candidate.safety_ratings)} categories\")\n",
    "        \n",
    "        print(\"\\nüí¨ Gemini's Response:\")\n",
    "        response_text = response.text if hasattr(response, 'text') else str(response)\n",
    "        print(f\"   '{response_text[:200]}{'...' if len(response_text) > 200 else ''}'\")\n",
    "        \n",
    "        print(\"\\nüéØ Testing model capabilities...\")\n",
    "        \n",
    "        # Test with a reasoning task\n",
    "        print(\"   Testing reasoning with a word problem...\")\n",
    "        reasoning_response = model.generate_content(\n",
    "            \"If a train travels 60 mph and needs to go 180 miles, how long will it take? Show your calculation.\",\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                max_output_tokens=80,\n",
    "                temperature=0\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        reasoning_text = reasoning_response.text if hasattr(reasoning_response, 'text') else str(reasoning_response)\n",
    "        print(f\"   Reasoning response: '{reasoning_text[:150]}{'...' if len(reasoning_text) > 150 else ''}'\")\n",
    "        \n",
    "        # Test with a creative task\n",
    "        print(\"   Testing creative writing...\")\n",
    "        creative_response = model.generate_content(\n",
    "            \"Write a haiku about artificial intelligence in exactly 3 lines.\",\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                max_output_tokens=50,\n",
    "                temperature=0.7\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        creative_text = creative_response.text if hasattr(creative_response, 'text') else str(creative_response)\n",
    "        print(f\"   Creative response: '{creative_text}'\")\n",
    "        \n",
    "        print(\"\\nüéâ GOOGLE GEMINI API TEST: PASSED\")\n",
    "        print(\"\\nüìã Capabilities verified:\")\n",
    "        print(\"   ‚úì API authentication\")\n",
    "        print(\"   ‚úì Content generation\")\n",
    "        print(\"   ‚úì Model configuration\")\n",
    "        print(\"   ‚úì Response parsing\")\n",
    "        print(\"   ‚úì Reasoning tasks\")\n",
    "        print(\"   ‚úì Creative tasks\")\n",
    "        print(\"   ‚úì Safety filtering\")\n",
    "        \n",
    "except ImportError as import_error:\n",
    "    print(f\"\\n‚ùå FAILED: Google AI library not installed\")\n",
    "    print(f\"Error: {import_error}\")\n",
    "    print(\"\\nüîß SOLUTION:\")\n",
    "    print(\"   1. Install Google AI library: pip install google-generativeai\")\n",
    "    print(\"   2. Re-run this test\")\n",
    "    print(\"\\n‚ùå GOOGLE GEMINI TEST: FAILED (MISSING LIBRARY)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå FAILED: Google Gemini API test failed\")\n",
    "    print(f\"\\nüîç Error Details:\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    print(f\"   Error message: {str(e)}\")\n",
    "    \n",
    "    # Parse different types of errors\n",
    "    error_str = str(e).lower()\n",
    "    \n",
    "    if \"api key\" in error_str or \"authentication\" in error_str or \"invalid\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: API key authentication issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your .env file\")\n",
    "        print(\"   2. Verify GOOGLE_API_KEY is correct\")\n",
    "        print(\"   3. Get new key from: https://console.cloud.google.com/apis/credentials\")\n",
    "        print(\"   4. Ensure Generative AI API is enabled in your project\")\n",
    "        \n",
    "    elif \"quota\" in error_str or \"limit\" in error_str or \"billing\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Quota exceeded or billing issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your Google Cloud billing: https://console.cloud.google.com/billing\")\n",
    "        print(\"   2. Enable billing for your project\")\n",
    "        print(\"   3. Check your API quotas and limits\")\n",
    "        print(\"   4. Wait if you've hit rate limits\")\n",
    "        \n",
    "    elif \"permission\" in error_str or \"forbidden\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Permissions issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Enable the Generative AI API in Google Cloud Console\")\n",
    "        print(\"   2. Check your project permissions\")\n",
    "        print(\"   3. Ensure your API key has the correct scopes\")\n",
    "        \n",
    "    elif \"connection\" in error_str or \"network\" in error_str:\n",
    "        print(\"\\nüí° DIAGNOSIS: Network connectivity issue\")\n",
    "        print(\"\\nüîß SOLUTION:\")\n",
    "        print(\"   1. Check your internet connection\")\n",
    "        print(\"   2. Try again in a few minutes\")\n",
    "        print(\"   3. Check if corporate firewall is blocking Google APIs\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nüí° DIAGNOSIS: Unexpected error\")\n",
    "        print(f\"\\nüîß SOLUTION:\")\n",
    "        print(f\"   1. Check Google Cloud status page\")\n",
    "        print(f\"   2. Verify your API key and project settings\")\n",
    "        print(f\"   3. Try again in a few minutes\")\n",
    "    \n",
    "    print(\"\\nüîç Full traceback:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    print(\"\\n‚ùå GOOGLE GEMINI API TEST: FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Embedding Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 7: EMBEDDING MODEL TEST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"NOTE: May take time to download model first time\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from config import Config\n",
    "    import numpy as np\n",
    "    \n",
    "    print(f\"Loading model: {Config.EMBEDDING_MODEL}\")\n",
    "    model = SentenceTransformer(Config.EMBEDDING_MODEL)\n",
    "    \n",
    "    test_texts = [\n",
    "        \"How do I configure user roles in Teamcenter Easy Plan?\",\n",
    "        \"What are the workflow setup procedures?\",\n",
    "        \"User management and permissions configuration\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Encoding test texts...\")\n",
    "    embeddings = model.encode(test_texts)\n",
    "    \n",
    "    similarity = np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))\n",
    "    \n",
    "    print(\"SUCCESS: Embedding model working!\")\n",
    "    print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "    print(f\"Number of test embeddings: {embeddings.shape[0]}\")\n",
    "    print(f\"Similarity between texts: {similarity:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"FAILED: Embedding test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: FAISS Vector Database Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STEP 8: FAISS VECTOR DATABASE TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "    import numpy as np\n",
    "    \n",
    "    dimension = 384\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    \n",
    "    print(f\"SUCCESS: FAISS index created (dimension: {dimension})\")\n",
    "    \n",
    "    num_vectors = 5\n",
    "    test_vectors = np.random.random((num_vectors, dimension)).astype('float32')\n",
    "    index.add(test_vectors)\n",
    "    \n",
    "    print(f\"SUCCESS: Added {num_vectors} test vectors\")\n",
    "    \n",
    "    query_vector = np.random.random((1, dimension)).astype('float32')\n",
    "    distances, indices = index.search(query_vector, k=3)\n",
    "    \n",
    "    print(\"SUCCESS: Vector search successful!\")\n",
    "    print(f\"Found {len(indices[0])} results\")\n",
    "    print(f\"Index size: {index.ntotal} vectors\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"FAILED: FAISS test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL SETUP STATUS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"üéØ CORE COMPONENTS (Required for basic functionality):\")\n",
    "print(\"   ‚úÖ Configuration Loading - Should PASS\")\n",
    "print(\"   ‚úÖ Dependencies Installation - Should PASS\") \n",
    "print(\"   ‚ùå Anthropic API (Primary) - Will FAIL (needs credits)\")\n",
    "print(\"   ‚úÖ Langfuse Tracking - Should PASS\")\n",
    "print(\"   ‚úÖ Embedding Model - Should PASS\")\n",
    "print(\"   ‚úÖ FAISS Vector Database - Should PASS\")\n",
    "\n",
    "print(\"\\nüîß FALLBACK/COMPARISON APIS (Optional):\")\n",
    "print(\"   ‚óã OpenAI GPT Models - Optional (for model comparison)\")\n",
    "print(\"   ‚óã Google Gemini - Optional (for model comparison)\")\n",
    "\n",
    "print(\"\\nüìä EXPECTED OUTCOMES:\")\n",
    "\n",
    "print(\"\\nüü¢ SHOULD PASS (5/6 core components):\")\n",
    "print(\"   ‚Ä¢ Configuration: All settings loaded, API keys detected\")\n",
    "print(\"   ‚Ä¢ Dependencies: All packages installed and importable\")\n",
    "print(\"   ‚Ä¢ Langfuse: Connection established, test tracking created\")\n",
    "print(\"   ‚Ä¢ Embeddings: Model downloaded and encoding working\")\n",
    "print(\"   ‚Ä¢ FAISS: Vector index created and search functional\")\n",
    "\n",
    "print(\"\\nüî¥ EXPECTED TO FAIL (1/6 core components):\")\n",
    "print(\"   ‚Ä¢ Anthropic API: 'Insufficient credits' error\")\n",
    "print(\"     ‚îî‚îÄ This is NORMAL and EXPECTED\")\n",
    "print(\"     ‚îî‚îÄ Solution: Add $5-10 credits to Anthropic account\")\n",
    "\n",
    "print(\"\\n‚≠ï OPTIONAL TESTS:\")\n",
    "print(\"   ‚Ä¢ OpenAI: Will SKIP if no key provided (that's fine)\")\n",
    "print(\"   ‚Ä¢ Google Gemini: Will SKIP if no key provided (that's fine)\")\n",
    "\n",
    "print(\"\\nüéâ SUCCESS CRITERIA:\")\n",
    "print(\"   üìà 5 out of 6 core tests passing = EXCELLENT\")\n",
    "print(\"   üìà Only Anthropic failing due to credits = EXPECTED\")\n",
    "print(\"   üìà Optional APIs skipped = PERFECTLY FINE\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS AFTER TESTING:\")\n",
    "\n",
    "print(\"\\n1. üí≥ ADD ANTHROPIC CREDITS (PRIORITY 1):\")\n",
    "print(\"   ‚Ä¢ Go to: https://console.anthropic.com/settings/billing\")\n",
    "print(\"   ‚Ä¢ Add minimum $5-10 credits\")\n",
    "print(\"   ‚Ä¢ Wait 2-3 minutes for processing\")\n",
    "print(\"   ‚Ä¢ Re-run Step 3 to verify\")\n",
    "\n",
    "print(\"\\n2. üìÅ PREPARE FOR DEVELOPMENT:\")\n",
    "print(\"   ‚Ä¢ Add sample documents to 'documents/' folder\")\n",
    "print(\"   ‚Ä¢ Review TODO.md for implementation roadmap\")\n",
    "print(\"   ‚Ä¢ Start with Phase 2: Core Data Models\")\n",
    "\n",
    "print(\"\\n3. üß™ OPTIONAL: TEST FALLBACK APIS:\")\n",
    "print(\"   ‚Ä¢ Get OpenAI key for model comparison\")\n",
    "print(\"   ‚Ä¢ Get Google key for additional model options\")\n",
    "print(\"   ‚Ä¢ These are NOT required for core functionality\")\n",
    "\n",
    "print(\"\\n‚ú® YOUR SYSTEM STATUS:\")\n",
    "if_all_pass = \"üéâ READY FOR DEVELOPMENT!\"\n",
    "if_anthropic_fails = \"üéØ ALMOST READY - Just need Anthropic credits!\"\n",
    "\n",
    "print(f\"   Expected status: {if_anthropic_fails}\")\n",
    "print(\"   Your RAG system foundation is solid!\")\n",
    "\n",
    "from datetime import datetime\n",
    "print(f\"\\n‚è∞ Test completed at: {datetime.now()}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}